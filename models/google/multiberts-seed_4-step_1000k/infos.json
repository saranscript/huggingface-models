{"modelId": "google/multiberts-seed_4-step_1000k", "sha": "e3bc2d4b5836d22bc6c47a7974dd8a6ac20703e8", "lastModified": "2021-11-06T03:34:00.000Z", "tags": ["pytorch", "tf", "bert", "pretraining", "en", "arxiv:2106.16163", "arxiv:1908.08962", "transformers", "multiberts", "multiberts-seed_4", "multiberts-seed_4-step_1000k", "license:apache-2.0", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf_model.h5"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["BertForPreTraining"], "model_type": "bert"}, "private": false, "downloads": 3, "library_name": "transformers", "likes": 0}