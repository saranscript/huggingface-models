---
license: apache-2.0
tags:
- generated_from_trainer
model-index:
- name: bert-large-uncased-finetuned-docvqa
  results:
  - task:
      name: Question Answering
      type: question-answering
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# bert-large-uncased-finetuned-docvqa

This model is a fine-tuned version of [bert-large-uncased](https://huggingface.co/bert-large-uncased) on an unknown dataset.
It achieves the following results on the evaluation set:
- Loss: 3.6367

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 2
- eval_batch_size: 2
- seed: 250500
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- num_epochs: 6

### Training results

| Training Loss | Epoch | Step   | Validation Loss |
|:-------------:|:-----:|:------:|:---------------:|
| 2.5228        | 0.05  | 1000   | 2.6645          |
| 2.4909        | 0.1   | 2000   | 2.8985          |
| 2.1679        | 0.16  | 3000   | 2.3551          |
| 1.9451        | 0.21  | 4000   | 2.2226          |
| 1.6814        | 0.26  | 5000   | 2.1590          |
| 1.8868        | 0.31  | 6000   | 2.6197          |
| 1.6618        | 0.36  | 7000   | 2.3632          |
| 1.8313        | 0.41  | 8000   | 2.4519          |
| 1.7017        | 0.47  | 9000   | 2.2682          |
| 1.8169        | 0.52  | 10000  | 2.4486          |
| 1.7074        | 0.57  | 11000  | 2.3862          |
| 1.7674        | 0.62  | 12000  | 2.1801          |
| 1.8134        | 0.67  | 13000  | 2.3032          |
| 1.8334        | 0.73  | 14000  | 2.4205          |
| 1.6819        | 0.78  | 15000  | 2.2398          |
| 1.5846        | 0.83  | 16000  | 2.3834          |
| 1.6758        | 0.88  | 17000  | 1.9683          |
| 1.6303        | 0.93  | 18000  | 2.3297          |
| 1.5652        | 0.98  | 19000  | 2.0581          |
| 1.3045        | 1.04  | 20000  | 2.4950          |
| 1.2393        | 1.09  | 21000  | 2.6622          |
| 1.1526        | 1.14  | 22000  | 2.3749          |
| 1.2631        | 1.19  | 23000  | 2.3915          |
| 1.1846        | 1.24  | 24000  | 2.2592          |
| 1.2731        | 1.3   | 25000  | 2.4239          |
| 1.3057        | 1.35  | 26000  | 2.2920          |
| 1.134         | 1.4   | 27000  | 2.3107          |
| 1.2017        | 1.45  | 28000  | 2.4271          |
| 1.2202        | 1.5   | 29000  | 2.1814          |
| 1.2179        | 1.56  | 30000  | 2.3365          |
| 1.2359        | 1.61  | 31000  | 2.1256          |
| 1.1964        | 1.66  | 32000  | 2.1720          |
| 1.269         | 1.71  | 33000  | 2.4363          |
| 1.1812        | 1.76  | 34000  | 2.2372          |
| 1.2187        | 1.81  | 35000  | 2.2318          |
| 1.1805        | 1.87  | 36000  | 2.3693          |
| 1.1458        | 1.92  | 37000  | 2.5128          |
| 1.1958        | 1.97  | 38000  | 2.1311          |
| 0.8924        | 2.02  | 39000  | 2.4635          |
| 0.869         | 2.07  | 40000  | 2.8231          |
| 0.8333        | 2.13  | 41000  | 2.6762          |
| 0.9194        | 2.18  | 42000  | 2.4588          |
| 0.8089        | 2.23  | 43000  | 2.6443          |
| 0.8612        | 2.28  | 44000  | 2.4300          |
| 0.7981        | 2.33  | 45000  | 2.7418          |
| 0.9765        | 2.38  | 46000  | 2.6543          |
| 0.8646        | 2.44  | 47000  | 2.5990          |
| 1.0316        | 2.49  | 48000  | 2.4625          |
| 0.9862        | 2.54  | 49000  | 2.4691          |
| 1.027         | 2.59  | 50000  | 2.4156          |
| 0.9412        | 2.64  | 51000  | 2.4204          |
| 0.9353        | 2.7   | 52000  | 2.4933          |
| 0.9509        | 2.75  | 53000  | 2.4708          |
| 0.9351        | 2.8   | 54000  | 2.5351          |
| 0.9968        | 2.85  | 55000  | 2.2506          |
| 1.025         | 2.9   | 56000  | 2.6317          |
| 1.627         | 2.95  | 57000  | 2.7843          |
| 0.9294        | 3.01  | 58000  | 2.9396          |
| 0.6043        | 3.06  | 59000  | 3.1560          |
| 0.7903        | 3.11  | 60000  | 2.8330          |
| 0.7373        | 3.16  | 61000  | 2.9422          |
| 0.6499        | 3.21  | 62000  | 3.0948          |
| 0.6411        | 3.27  | 63000  | 2.7900          |
| 0.625         | 3.32  | 64000  | 2.5268          |
| 0.6264        | 3.37  | 65000  | 2.8701          |
| 0.6143        | 3.42  | 66000  | 3.2544          |
| 0.6286        | 3.47  | 67000  | 2.6208          |
| 0.739         | 3.53  | 68000  | 2.8107          |
| 0.5981        | 3.58  | 69000  | 2.8073          |
| 0.6502        | 3.63  | 70000  | 2.6293          |
| 0.6548        | 3.68  | 71000  | 2.9501          |
| 0.7243        | 3.73  | 72000  | 2.7917          |
| 0.598         | 3.78  | 73000  | 2.9341          |
| 0.6159        | 3.84  | 74000  | 2.7629          |
| 0.5905        | 3.89  | 75000  | 2.6441          |
| 0.6393        | 3.94  | 76000  | 2.6660          |
| 0.677         | 3.99  | 77000  | 2.7616          |
| 0.3281        | 4.04  | 78000  | 3.6873          |
| 0.4524        | 4.1   | 79000  | 3.3441          |
| 0.3994        | 4.15  | 80000  | 3.3129          |
| 0.4686        | 4.2   | 81000  | 3.1813          |
| 0.5293        | 4.25  | 82000  | 2.9088          |
| 0.3961        | 4.3   | 83000  | 3.0765          |
| 0.4406        | 4.35  | 84000  | 3.1254          |
| 0.401         | 4.41  | 85000  | 3.2415          |
| 0.4594        | 4.46  | 86000  | 3.0691          |
| 0.4523        | 4.51  | 87000  | 3.0493          |
| 0.4719        | 4.56  | 88000  | 3.1352          |
| 0.4895        | 4.61  | 89000  | 2.8991          |
| 0.423         | 4.67  | 90000  | 3.1738          |
| 0.3984        | 4.72  | 91000  | 3.1862          |
| 0.4206        | 4.77  | 92000  | 3.1213          |
| 0.4587        | 4.82  | 93000  | 3.0030          |
| 0.381         | 4.87  | 94000  | 3.3218          |
| 0.4138        | 4.92  | 95000  | 3.1529          |
| 0.4003        | 4.98  | 96000  | 3.1375          |
| 0.2098        | 5.03  | 97000  | 3.7443          |
| 0.2334        | 5.08  | 98000  | 3.7359          |
| 0.2534        | 5.13  | 99000  | 3.7814          |
| 0.3067        | 5.18  | 100000 | 3.7128          |
| 0.2363        | 5.24  | 101000 | 3.6091          |
| 0.2652        | 5.29  | 102000 | 3.4015          |
| 0.3311        | 5.34  | 103000 | 3.4793          |
| 0.2344        | 5.39  | 104000 | 3.6792          |
| 0.2741        | 5.44  | 105000 | 3.5385          |
| 0.2896        | 5.5   | 106000 | 3.8118          |
| 0.2071        | 5.55  | 107000 | 3.8690          |
| 0.3023        | 5.6   | 108000 | 3.7087          |
| 0.3299        | 5.65  | 109000 | 3.4925          |
| 0.1943        | 5.7   | 110000 | 3.6739          |
| 0.2488        | 5.75  | 111000 | 3.7614          |
| 0.3138        | 5.81  | 112000 | 3.5156          |
| 0.2555        | 5.86  | 113000 | 3.6056          |
| 0.2918        | 5.91  | 114000 | 3.6533          |
| 0.2751        | 5.96  | 115000 | 3.6367          |


### Framework versions

- Transformers 4.10.0
- Pytorch 1.8.0+cu101
- Datasets 1.11.0
- Tokenizers 0.10.3
