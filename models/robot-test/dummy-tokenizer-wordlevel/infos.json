{"modelId": "robot-test/dummy-tokenizer-wordlevel", "sha": "ae57c419a98ae4ddf991c6a1af4a8ce94745f45c", "lastModified": "2021-06-30T08:39:22.000Z", "tags": [], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}], "config": null, "private": false, "downloads": 0, "likes": 0}