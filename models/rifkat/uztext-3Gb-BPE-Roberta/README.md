<p><b>UzRoBerta model.</b>

Pre-prepared model in Uzbek (Cyrillic and latin script) to model the masked language and predict the next sentences.

<p><b>Training data.</b>

UzBERT model was pretrained on &asymp;2M news articles (&asymp;3Gb).