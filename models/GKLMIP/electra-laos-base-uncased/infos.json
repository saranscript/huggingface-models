{"modelId": "GKLMIP/electra-laos-base-uncased", "sha": "acaee663087c8b01837470a659deaa3c61ddabfa", "lastModified": "2021-07-31T06:21:25.000Z", "tags": ["pytorch", "electra", "pretraining", "transformers", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "lo.wiki.bpe.vs25000.model"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["ElectraForPreTraining"], "model_type": "electra"}, "private": false, "downloads": 3, "library_name": "transformers", "likes": 0}