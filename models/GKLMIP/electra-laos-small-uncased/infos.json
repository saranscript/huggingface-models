{"modelId": "GKLMIP/electra-laos-small-uncased", "sha": "ff5c82ec50fecb177ab7a3c88e07b6da61eaa0c3", "lastModified": "2021-07-31T06:36:30.000Z", "tags": ["pytorch", "electra", "pretraining", "transformers", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "lo.wiki.bpe.vs25000.model"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["ElectraForPreTraining"], "model_type": "electra"}, "private": false, "downloads": 1, "library_name": "transformers", "likes": 0}