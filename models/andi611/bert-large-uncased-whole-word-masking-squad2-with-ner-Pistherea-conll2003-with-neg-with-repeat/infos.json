{"modelId": "andi611/bert-large-uncased-whole-word-masking-squad2-with-ner-Pistherea-conll2003-with-neg-with-repeat", "sha": "6a0488e722a821e9003858e1dd661fef072d00db", "lastModified": "2021-10-02T16:53:01.000Z", "tags": ["pytorch", "bert", "question-answering", "en", "dataset:squad_v2", "dataset:conll2003", "transformers", "license:cc-by-4.0", "generated_from_trainer", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "question-answering", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": ".gitignore"}, {"rfilename": "README.md"}, {"rfilename": "all_results.json"}, {"rfilename": "config.json"}, {"rfilename": "log.log"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "train_results.json"}, {"rfilename": "training_args.bin"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["BertForQuestionAnswering"], "model_type": "bert"}, "private": false, "downloads": 0, "library_name": "transformers", "likes": 0}