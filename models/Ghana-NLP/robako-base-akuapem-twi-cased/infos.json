{"modelId": "Ghana-NLP/robako-base-akuapem-twi-cased", "sha": "3c65d79a4469412c460d90520a3b3b52f33c257a", "lastModified": "2021-05-20T11:53:32.000Z", "tags": ["pytorch", "tf", "jax", "roberta", "fill-mask", "transformers", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "config.json"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "merges.txt"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "tf_model.h5"}, {"rfilename": "train.log"}, {"rfilename": "training_args.bin"}, {"rfilename": "vocab.json"}], "config": {"architectures": ["RobertaForMaskedLM"], "model_type": "roberta"}, "private": false, "downloads": 7, "library_name": "transformers", "likes": 0}