{"modelId": "Ghana-NLP/distilabena-base-v2-akuapem-twi-cased", "sha": "1924d0de61e611f7523a241716c047b65c11c4ef", "lastModified": "2020-10-22T06:08:50.000Z", "tags": ["pytorch", "tf", "distilbert", "fill-mask", "transformers", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "tf_model.h5"}, {"rfilename": "training_args.bin"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["DistilBertForMaskedLM"], "model_type": "distilbert"}, "private": false, "downloads": 10, "library_name": "transformers", "likes": 0}