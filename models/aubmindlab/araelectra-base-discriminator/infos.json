{"modelId": "aubmindlab/araelectra-base-discriminator", "sha": "9ebafb3eb00b864300bd8b04d7bd2cf24046bd26", "lastModified": "2021-07-31T16:34:09.000Z", "tags": ["pytorch", "tf", "electra", "pretraining", "ar", "dataset:wikipedia", "dataset:OSIAN", "dataset:1.5B Arabic Corpus", "dataset:OSCAR Arabic Unshuffled", "arxiv:2012.15516", "transformers", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf1_model.tar.gz"}, {"rfilename": "tf_model.h5"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["ElectraForPreTraining"], "model_type": "electra"}, "private": false, "downloads": 844, "library_name": "transformers", "likes": 0}