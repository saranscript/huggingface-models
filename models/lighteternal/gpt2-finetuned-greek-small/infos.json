{"modelId": "lighteternal/gpt2-finetuned-greek-small", "sha": "44ce2064df77b9cf528232a386182df8f980ca04", "lastModified": "2021-05-23T08:32:03.000Z", "tags": ["pytorch", "jax", "gpt2", "text-generation", "el", "transformers", "causal-lm", "license:apache-2.0"], "pipeline_tag": "text-generation", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "GPT2el.png"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "merges.txt"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.json"}], "config": {"architectures": ["GPT2LMHeadModel"], "model_type": "gpt2", "task_specific_params": {"text-generation": {"do_sample": true, "max_length": 25, "top_k": 80, "repetition_penalty": 1.2, "add_special_tokens": false, "temperature": 1, "top_p": 0.95}}}, "private": false, "downloads": 15, "library_name": "transformers", "likes": 0}