{"modelId": "KoichiYasuoka/roberta-classical-chinese-large-sentence-segmentation", "sha": "7e2fb3ab1680d82e79df0f314f84994c8ec87d5a", "lastModified": "2021-12-10T00:35:08.000Z", "tags": ["pytorch", "roberta", "token-classification", "lzh", "transformers", "classical chinese", "literary chinese", "ancient chinese", "sentence segmentation", "license:apache-2.0", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "token-classification", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["RobertaForTokenClassification"], "model_type": "roberta"}, "private": false, "downloads": 40, "library_name": "transformers", "likes": 1}