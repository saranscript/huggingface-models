{"modelId": "nlp-waseda/roberta-base-japanese", "sha": "fa98d0401e921b69c14f9104cb1426c7b549c6d1", "lastModified": "2021-12-23T14:49:32.000Z", "tags": ["pytorch", "roberta", "fill-mask", "ja", "dataset:wikipedia", "dataset:cc100", "transformers", "license:cc-by-sa-4.0", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "spiece.model"}, {"rfilename": "tokenizer_config.json"}], "config": {"architectures": ["RobertaForMaskedLM"], "model_type": "roberta"}, "private": false, "downloads": 2791, "library_name": "transformers", "likes": 7}