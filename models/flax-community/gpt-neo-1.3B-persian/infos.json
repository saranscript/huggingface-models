{"modelId": "flax-community/gpt-neo-1.3B-persian", "sha": "69dd1b08016423991aa68518bbcc0701b64cd87a", "lastModified": "2021-07-15T05:47:50.000Z", "tags": ["gpt_neo", "text-generation", "transformers"], "pipeline_tag": "text-generation", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "config.json"}, {"rfilename": "merges.txt"}, {"rfilename": "tokenizer.json"}, {"rfilename": "vocab.json"}, {"rfilename": "notes/.keep"}, {"rfilename": "src/convert_flax_to_pytorch.py"}, {"rfilename": "src/convert_flax_to_tf.py"}, {"rfilename": "src/create_config.py"}, {"rfilename": "src/create_dataset.py"}, {"rfilename": "src/data_utils.py"}, {"rfilename": "src/dictionary.py"}, {"rfilename": "src/normalizer.py"}, {"rfilename": "src/requirements.txt"}, {"rfilename": "src/run.sh"}, {"rfilename": "src/run_clm_flax.py"}, {"rfilename": "src/run_clm_flax_with_ckpts.py"}, {"rfilename": "src/run_config.sh"}, {"rfilename": "src/run_dataset.sh"}, {"rfilename": "src/run_tokenizer.sh"}, {"rfilename": "src/train_tokenizer.py"}, {"rfilename": "src/regexes/__init__.py"}, {"rfilename": "src/regexes/currency.py"}, {"rfilename": "src/regexes/email.py"}, {"rfilename": "src/regexes/latin.py"}, {"rfilename": "src/regexes/number.py"}, {"rfilename": "src/regexes/persian.py"}, {"rfilename": "src/regexes/phone.py"}, {"rfilename": "src/regexes/punk.py"}, {"rfilename": "src/regexes/quote.py"}, {"rfilename": "src/regexes/url.py"}, {"rfilename": "src/regexes/__pycache__/__init__.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/currency.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/email.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/latin.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/number.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/persian.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/phone.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/punk.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/quote.cpython-38.pyc"}, {"rfilename": "src/regexes/__pycache__/url.cpython-38.pyc"}], "config": {"architectures": ["GPTNeoForCausalLM"], "model_type": "gpt_neo", "task_specific_params": {"text-generation": {"do_sample": true, "max_length": 50, "temperature": 0.9}}}, "private": false, "downloads": 6, "library_name": "transformers", "likes": 0}