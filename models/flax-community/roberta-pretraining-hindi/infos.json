{"modelId": "flax-community/roberta-pretraining-hindi", "sha": "91428432765ef16c941482f0c180488a8e807766", "lastModified": "2021-07-15T15:44:11.000Z", "tags": ["pytorch", "jax", "tensorboard", "roberta", "fill-mask", "transformers", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "create_config.py"}, {"rfilename": "events.out.tfevents.1625416432.t1v-n-9df4ce0e-w-0.447041.3.v2"}, {"rfilename": "events.out.tfevents.1625418057.t1v-n-9df4ce0e-w-0.452509.3.v2"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "flax_to_torch.py"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "run.sh"}, {"rfilename": "run_mlm_flax.py"}, {"rfilename": "tokenizer.json"}, {"rfilename": "train_tokenizer.py"}], "config": {"architectures": ["RobertaForMaskedLM"], "model_type": "roberta"}, "private": false, "downloads": 31, "library_name": "transformers", "likes": 0}