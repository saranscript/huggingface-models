{"modelId": "GroNLP/gpt2-small-dutch-embeddings", "sha": "845a4c7cdae998c888f6ed5932a0a2a1732d0104", "lastModified": "2021-05-21T09:54:45.000Z", "tags": ["pytorch", "tf", "jax", "gpt2", "text-generation", "nl", "arxiv:2012.05628", "transformers", "adaption", "recycled", "gpt2-small"], "pipeline_tag": "text-generation", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "merges.txt"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf_model.h5"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.json"}], "config": {"architectures": ["GPT2LMHeadModel"], "model_type": "gpt2", "task_specific_params": {"text-generation": {"do_sample": true, "max_length": 100, "no_repeat_ngram_size": 4, "num_beams": 10, "repetition_penalty": 10, "temperature": 2, "top_k": 20, "top_p": 0.9}}}, "private": false, "downloads": 6, "library_name": "transformers", "likes": 0}