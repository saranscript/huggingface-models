{"modelId": "cardiffnlp/twitter-roberta-base-irony", "sha": "72213835791c86ac7cade4acef91820bc9f1dc57", "lastModified": "2021-05-20T15:03:56.000Z", "tags": ["pytorch", "tf", "jax", "roberta", "text-classification", "arxiv:2010.12421", "transformers", "infinity_compatible"], "pipeline_tag": "text-classification", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "merges.txt"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf_model.h5"}, {"rfilename": "vocab.json"}, {"rfilename": ".ipynb_checkpoints/README-checkpoint.md"}], "config": {"architectures": ["RobertaForSequenceClassification"], "model_type": "roberta"}, "private": false, "downloads": 3158, "library_name": "transformers", "likes": 1}