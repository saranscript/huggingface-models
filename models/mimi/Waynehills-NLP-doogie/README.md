---
tags:
- generated_from_trainer
model-index:
- name: Waynehills-NLP-doogie
  results: []
---

<!-- This model card has been generated automatically according to the information the Trainer had access to. You
should probably proofread and complete it, then remove this comment. -->

# Waynehills-NLP-doogie

This model is a fine-tuned version of [KETI-AIR/ke-t5-base-ko](https://huggingface.co/KETI-AIR/ke-t5-base-ko) on the None dataset.
It achieves the following results on the evaluation set:
- Loss: 2.9188

## Model description

More information needed

## Intended uses & limitations

More information needed

## Training and evaluation data

More information needed

## Training procedure

### Training hyperparameters

The following hyperparameters were used during training:
- learning_rate: 2e-05
- train_batch_size: 2
- eval_batch_size: 2
- seed: 42
- optimizer: Adam with betas=(0.9,0.999) and epsilon=1e-08
- lr_scheduler_type: linear
- lr_scheduler_warmup_steps: 10
- num_epochs: 5

### Training results

| Training Loss | Epoch | Step  | Validation Loss |
|:-------------:|:-----:|:-----:|:---------------:|
| 28.2167       | 0.06  | 1000  | 9.7030          |
| 10.4479       | 0.12  | 2000  | 7.5450          |
| 8.0306        | 0.19  | 3000  | 6.1969          |
| 6.503         | 0.25  | 4000  | 5.3015          |
| 5.5406        | 0.31  | 5000  | 4.6363          |
| 4.7299        | 0.38  | 6000  | 4.0431          |
| 3.9263        | 0.44  | 7000  | 3.6313          |
| 3.4111        | 0.5   | 8000  | 3.4830          |
| 3.0517        | 0.56  | 9000  | 3.3294          |
| 2.7524        | 0.62  | 10000 | 3.2077          |
| 2.5402        | 0.69  | 11000 | 3.1094          |
| 2.3228        | 0.75  | 12000 | 3.1099          |
| 2.1513        | 0.81  | 13000 | 3.0284          |
| 2.0418        | 0.88  | 14000 | 3.0155          |
| 1.8875        | 0.94  | 15000 | 3.0241          |
| 1.756         | 1.0   | 16000 | 3.0165          |
| 1.6489        | 1.06  | 17000 | 2.9849          |
| 1.5788        | 1.12  | 18000 | 2.9496          |
| 1.5368        | 1.19  | 19000 | 2.9500          |
| 1.4467        | 1.25  | 20000 | 3.0133          |
| 1.381         | 1.31  | 21000 | 2.9631          |
| 1.3451        | 1.38  | 22000 | 3.0159          |
| 1.2917        | 1.44  | 23000 | 2.9906          |
| 1.2605        | 1.5   | 24000 | 3.0006          |
| 1.2003        | 1.56  | 25000 | 2.9797          |
| 1.1987        | 1.62  | 26000 | 2.9253          |
| 1.1703        | 1.69  | 27000 | 3.0044          |
| 1.1474        | 1.75  | 28000 | 2.9216          |
| 1.0816        | 1.81  | 29000 | 2.9645          |
| 1.0709        | 1.88  | 30000 | 3.0439          |
| 1.0476        | 1.94  | 31000 | 3.0844          |
| 1.0645        | 2.0   | 32000 | 2.9434          |
| 1.0204        | 2.06  | 33000 | 2.9386          |
| 0.9901        | 2.12  | 34000 | 3.0452          |
| 0.9911        | 2.19  | 35000 | 2.9798          |
| 0.9706        | 2.25  | 36000 | 2.9919          |
| 0.9461        | 2.31  | 37000 | 3.0279          |
| 0.9577        | 2.38  | 38000 | 2.9615          |
| 0.9466        | 2.44  | 39000 | 2.9988          |
| 0.9486        | 2.5   | 40000 | 2.9133          |
| 0.9201        | 2.56  | 41000 | 3.0004          |
| 0.896         | 2.62  | 42000 | 2.9626          |
| 0.8893        | 2.69  | 43000 | 2.9667          |
| 0.9028        | 2.75  | 44000 | 2.9543          |
| 0.897         | 2.81  | 45000 | 2.8760          |
| 0.8664        | 2.88  | 46000 | 2.9894          |
| 0.8719        | 2.94  | 47000 | 2.8456          |
| 0.8491        | 3.0   | 48000 | 2.9713          |
| 0.8402        | 3.06  | 49000 | 2.9738          |
| 0.8484        | 3.12  | 50000 | 2.9361          |
| 0.8304        | 3.19  | 51000 | 2.8945          |
| 0.8208        | 3.25  | 52000 | 2.9625          |
| 0.8074        | 3.31  | 53000 | 3.0054          |
| 0.8226        | 3.38  | 54000 | 2.9405          |
| 0.8185        | 3.44  | 55000 | 2.9047          |
| 0.8352        | 3.5   | 56000 | 2.9016          |
| 0.8289        | 3.56  | 57000 | 2.9490          |
| 0.7918        | 3.62  | 58000 | 2.9621          |
| 0.8212        | 3.69  | 59000 | 2.9341          |
| 0.7955        | 3.75  | 60000 | 2.9167          |
| 0.7724        | 3.81  | 61000 | 2.9409          |
| 0.8169        | 3.88  | 62000 | 2.8925          |
| 0.7862        | 3.94  | 63000 | 2.9314          |
| 0.803         | 4.0   | 64000 | 2.9271          |
| 0.7595        | 4.06  | 65000 | 2.9263          |
| 0.7931        | 4.12  | 66000 | 2.9400          |
| 0.7759        | 4.19  | 67000 | 2.9501          |
| 0.7859        | 4.25  | 68000 | 2.9133          |
| 0.805         | 4.31  | 69000 | 2.8785          |
| 0.7649        | 4.38  | 70000 | 2.9060          |
| 0.7692        | 4.44  | 71000 | 2.8868          |
| 0.7692        | 4.5   | 72000 | 2.9045          |
| 0.7798        | 4.56  | 73000 | 2.8951          |
| 0.7812        | 4.62  | 74000 | 2.9068          |
| 0.7533        | 4.69  | 75000 | 2.9129          |
| 0.7527        | 4.75  | 76000 | 2.9157          |
| 0.7652        | 4.81  | 77000 | 2.9053          |
| 0.7633        | 4.88  | 78000 | 2.9190          |
| 0.7437        | 4.94  | 79000 | 2.9251          |
| 0.7653        | 5.0   | 80000 | 2.9188          |


### Framework versions

- Transformers 4.12.5
- Pytorch 1.10.0+cu111
- Datasets 1.5.0
- Tokenizers 0.10.3
