{"modelId": "Maltehb/aelaectra-danish-electra-small-cased", "sha": "106e95e10eef7b40441db59d1ac98bef3d78dd0a", "lastModified": "2021-11-23T06:39:44.000Z", "tags": ["pytorch", "tf", "electra", "pretraining", "da", "dataset:DAGW", "arxiv:2003.10555", "arxiv:1810.04805", "arxiv:2005.03521", "transformers", "\u00e6l\u00e6ctra", "danish", "ELECTRA-Small", "replaced token detection", "license:mit", "co2_eq_emissions", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf_model.h5"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["ElectraForPreTraining"], "model_type": "electra"}, "private": false, "downloads": 1571, "library_name": "transformers", "likes": 1}