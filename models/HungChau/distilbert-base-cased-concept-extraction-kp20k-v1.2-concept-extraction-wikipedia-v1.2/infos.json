{"modelId": "HungChau/distilbert-base-cased-concept-extraction-kp20k-v1.2-concept-extraction-wikipedia-v1.2", "sha": "da0c9ebdfbef63d9cbb2dc9ece2380b0f5dbfbf9", "lastModified": "2021-11-18T19:35:39.000Z", "tags": ["pytorch", "distilbert", "token-classification", "transformers", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "token-classification", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["DistilBertForTokenClassification"], "model_type": "distilbert"}, "private": false, "downloads": 11, "library_name": "transformers", "likes": 0}