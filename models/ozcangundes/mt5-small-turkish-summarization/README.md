---
language: tr
datasets:
- MLSUM
pipeline_tag: summarization
license: mit
---

# mT5-small based Turkish Summarization System

[Google's Multilingual T5-small](https://github.com/google-research/multilingual-t5) is fine-tuned on [MLSUM Turkish news dataset](https://github.com/recitalAI/MLSUM) for **Summarization** downstream task by using Pytorch Lightning.âš¡  

mT5 small model has 300 million parameters and model size is about 1.2GB. Therefore, it takes significant amount of time to fine tune it. The model is trained with 10 epochs, 8 batch size and 10e-4 learning rate. It took almost 4 hours. The max news length is kept as 784 and max summary length is determined as 64. 


**Important Note**: mT5 was only pre-trained on [mC4](https://www.tensorflow.org/datasets/catalog/c4#c4multilingual)
excluding any supervised training. Therefore, the mT5 model has to be fine-tuned before it is useable on a downstream task.

## Dataset

MLSUM dataset has more than 250K Turkish news with their related summaries. Since the mT5 model size and vocabulary is so large, 20K data is used for training and 4K data is used for validation. For more information about the dataset, please read this [great paper](https://arxiv.org/abs/2004.14900).
## Usage ğŸš€

```python
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM

tokenizer = AutoTokenizer.from_pretrained("ozcangundes/mt5-small-turkish-summarization")

model = AutoModelForSeq2SeqLM.from_pretrained("ozcangundes/mt5-small-turkish-summarization")

def generate_summary(main_news):
  source_encoding=tokenizer(
    main_news,
    max_length=784,
    padding="max_length",
    truncation=True,
    return_attention_mask=True,
    add_special_tokens=True,
    return_tensors="pt")
  
  generated_ids=model.generate(
      input_ids=source_encoding["input_ids"],
      attention_mask=source_encoding["attention_mask"],
      num_beams=2,
      max_length=120,
      repetition_penalty=2.5,
      length_penalty=2.0,
      early_stopping=True,
      use_cache=True
  )

  preds=[tokenizer.decode(gen_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) 
         for gen_id in generated_ids]

  return "".join(preds)
```

### Example 1
```python
main_news= "Final etabÄ±nÄ±n Ã¼Ã§Ã¼ncÃ¼ karÅŸÄ±laÅŸmasÄ± 29 Nisan Pazartesi gÃ¼nÃ¼ saat 18.00 â€™ de Burhan Felek
           Voleybol Salonu â€™ nda oynanacak . Sezonu FIVB KulÃ¼pler DÃ¼nya ÅampiyonluÄŸu ile aÃ§an ve CEV 
           Avrupa Åampiyonlar Ligi'ni Ã¼Ã§Ã¼ncÃ¼ olarak tamamlayan VakÄ±fBank KadÄ±n Voleybol TakÄ±mÄ± , 
           Vestel Venus Sultanlar Ligi final serisi ikinci maÃ§Ä±nda EczacÄ±baÅŸÄ± VitrA'yÄ± VakÄ±fBank 
           Spor SarayÄ±'nda 16-25 , 25-10 , 25-18 ve 25-17'lik setlerle 3-1 maÄŸlup ederek seride durumu
           1-1 ' e getirdi . Ä°lk setini 25-16 kaybettiÄŸi karÅŸÄ±laÅŸmanÄ±n ikinci setinde etkili servisler
           kullanan sarÄ±-siyahlÄ±lar , teknik molasÄ±na 12-5 Ã¶nde girdiÄŸi seti 25-10 almayÄ± baÅŸardÄ± . 
           Etkili servis performansÄ±nÄ± Ã¼Ã§Ã¼ncÃ¼ sette de sÃ¼rdÃ¼ren VakÄ±fBank , teknik molasÄ±na 12-5 Ã¶nde 
           girdiÄŸi seti 25-18 alarak , karÅŸÄ±laÅŸmada 2-1 Ã¶ne geÃ§ti . DÃ¶rdÃ¼ncÃ¼ sette rakibinin geri dÃ¶nÃ¼ÅŸÃ¼ne 
           izin vermeyen VakÄ±fBank , seti 25-17 , maÃ§Ä± da 3-1 kazanarak seride durumu eÅŸitledi."
    
generate_summary(main_news)

#original summary -> "Vestel Venus Sultanlar Ligi final etabÄ± ikinci karÅŸÄ±laÅŸmasÄ±nda VakÄ±fBank 
                  kendi sahasÄ±nda EczacÄ±baÅŸÄ± VitrA'yÄ± 3-1 maÄŸlup etti ve seride durumu 1-1 ' e getirdi ."

#output -> "CEV Avrupa Åampiyonlar Ligi'ni Ã¼Ã§Ã¼ncÃ¼ olarak tamamlayan VakÄ±fBank KadÄ±n Voleybol TakÄ±mÄ±, 
            Vestel Venus Sultanlar Ligi final serisi ikinci maÃ§Ä±nda EczacÄ±baÅŸÄ± VitrA'yÄ± 3-1 maÄŸlup 
            ederek seride durumu 1-1'e getirdi."
```

### Example 2
```python
main_news="2023'te yerli tank motoru : Bir taraftan da tankÄ±n motorunu yerlileÅŸtirmeye Ã§alÄ±ÅŸtÄ±klarÄ±nÄ± 
          ifade eden Ã–ztÃ¼rk , ÅŸu deÄŸerlendirmelerde bulundu : `` Bin 500 beygirlik , ÅŸanzÄ±manÄ±yla beraber 
          motoru yerlileÅŸtirmeye Ã§alÄ±ÅŸÄ±yoruz . Bu da bir aksilik Ã§Ä±kmazsa ilk tankÄ±mÄ±zÄ±n Ã¼zerine 
          2023'te koyacaÄŸÄ±z . Bundan sonra hiÃ§bir Ã¼lkeye baÄŸÄ±mlÄ±lÄ±ÄŸÄ±mÄ±z kalmadan bu araÃ§larÄ± Ã¼retmeye
           devam edeceÄŸiz . SorumluluÄŸumuzun aÄŸÄ±r olduÄŸunu biliyoruz . Ãœlkemize hizmet etmeye Ã§alÄ±ÅŸÄ±yoruz .
           Bunu daha da ileriye gÃ¶tÃ¼rmek iÃ§in elimizden gelen Ã§abayÄ± sarf ediyoruz . Ama bu tek baÅŸÄ±nÄ±za
           yapÄ±lan bir operasyon deÄŸil . TÃ¼rkiye'deki yerli firmalarla beraber ortaklaÅŸa bu iÅŸi yÃ¼rÃ¼tmeye Ã§alÄ±ÅŸÄ±yoruz."
    
generate_summary(main_news)

#output -> "TÃœRKÄ°YE'de bir taraftan da tankÄ±n motorunu yerlileÅŸtirmeye Ã§alÄ±ÅŸtÄ±klarÄ±nÄ± belirten Ã–ztÃ¼rk, 
            `` Bin 500 beygirlik, ÅŸanzÄ±manÄ±yla beraber motoru yerlileÅŸtirmeye Ã§alÄ±ÅŸÄ±yoruz. Bu da bir 
            aksilik Ã§Ä±kmazsa ilk tankÄ±mÄ±zÄ±n Ã¼zerine 2023'te koyacaÄŸÄ±z.'' dedi."
```

Created by Ã–zcan GÃ¼ndeÅŸ âœŒï¸
---

Twitter: <a href="https://twitter.com/ozcangundes" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/twitter.svg" alt="ozcangundes" height="30" width="30" /></a>
Linkedin: <a href="https://www.linkedin.com/in/%C3%B6zcan-g%C3%BCnde%C5%9F-7693055b/" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/linkedin.svg" alt="13198517" height="30" width="30" /></a>
Medium: <a href="https://medium.com/@ozcangundes" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/medium.svg" alt="@ozcangundes" height="30" width="30" /></a>
Github: <a href="https://github.com/ozcangundes" target="blank"><img align="center" src="https://cdn.jsdelivr.net/npm/simple-icons@3.0.1/icons/github.svg" alt="@ozcangundes" height="30" width="30" /></a>
