---
language: 
- fr

license: mit

pipeline_tag: sentence-similarity

widget:
- source_sentence: "Bonsoir"
  sentences:
    - "Salut !"
    - "Hello"
    - "Bonsoir!"
    - "Bonsouar!"
    - "Bonsouar !"
    - "De rien"
    - "LUL LUL"
  example_title: "Coucou"
- source_sentence: "elle s'en sort bien"
  sentences:
    - "elle a raison"
    - "elle a tellement raison"
    - "Elle a pas tort"
    - "C'est bien ce qu'elle dit l√†"
    - "Hello"
  example_title: "Raison or not"
- source_sentence: "et la question √©nerg√©tique n'est pas politique ?"
  sentences:
    - "C'est le nucl√©aire militaire qui a entach√© le nucl√©aire pour l'√©nergie."
    - "La fusion nucl√©aire c'est pas pour maintenant malheureusement"
    - "le pro nucl√©aire redevient acceptable √† gauche j'ai l'impression"
    - "La mer √† Nantes?"
    - "c'est bien un olivier pour l'upr"
    - "Moi je vois juste sa lavalli√®re"
  example_title: "Nucl√©aire"

tags:
- sentence-transformers
- feature-extraction
- sentence-similarity
- transformers
- twitch
- convbert
---


## Mod√®le de repr√©sentation d'un message Twitch √† l'aide de ConvBERT

Mod√®le [sentence-transformers](https://www.SBERT.net): cela permet de mapper une s√©quence de texte en un vecteur num√©rique de dimension 256 et peut √™tre utilis√© pour des t√¢ches de clustering ou de recherche s√©mantique.

L'exp√©rimentation men√©e au sein de Lincoln avait pour principal objectif de mettre en ≈ìuvre des techniques NLP from scratch sur un corpus de messages issus d‚Äôun chat Twitch. Ces derniers sont exprim√©s en fran√ßais, mais sur une plateforme internet avec le vocabulaire internet que cela implique (fautes, vocabulaire communautaires, abr√©viations, anglicisme, emotes, ...). 

Apr√®s avoir entrain√© un mod√®le `ConvBert` puis `MLM` (cf section smod√®les), nous avons entrain√© un mod√®le _sentence-transformers_ √† l'aide du framework d'apprentissage [SimCSE](https://www.sbert.net/examples/unsupervised_learning/SimCSE/README.html) en non supervis√©e. 

L'objectif est de sp√©cialiser la moyenne des tokens _CLS_ de chaque token de la s√©quence pour repr√©senter un vecteur num√©rique coh√©rent avec l'ensemble du corpus. _SimCSE_ cr√©e fictivement des exemples positifs et n√©gatifs supervis√©es √† l'aide du dropout pour revenir √† une t√¢che classique.

_Nous garantissons pas la stabilit√© du mod√®le sur le long terme. Mod√®le r√©alis√© dans le cadre d'un POC._


## Usage (Sentence-Transformers)

Using this model becomes easy when you have [sentence-transformers](https://www.SBERT.net) installed:

```
pip install -U sentence-transformers
```

Then you can use the model like this:

```python
from sentence_transformers import SentenceTransformer
sentences = ["This is an example sentence", "Each sentence is converted"]

model = SentenceTransformer('2021twitchfr-conv-bert-small-mlm-simcse')
embeddings = model.encode(sentences)
print(embeddings)
```

## Semantic Textual Similarity

```python
from sentence_transformers import SentenceTransformer, models, util

# Two lists of sentences
sentences1 = ['zackFCZack',
              'Team bons petits plats',
              'sa commence a quelle heure de base popcorn ?',
              'BibleThump']

sentences2 = ['zack titulaire',
              'salade de pates c une dinguerie',
              '√ßa commence √† √™tre long la',
              'NotLikeThis']

# Compute embedding for both lists
embeddings1 = model.encode(sentences1, convert_to_tensor=True)
embeddings2 = model.encode(sentences2, convert_to_tensor=True)

# Compute cosine-similarits
cosine_scores = util.cos_sim(embeddings1, embeddings2)

# Output the pairs with their score
for i in range(len(sentences1)):
    print("Score: {:.4f} | \"{}\" -vs- \"{}\" ".format(cosine_scores[i][i], sentences1[i], sentences2[i]))
# Score: 0.5783 | "zackFCZack" -vs- "zack titulaire" 
# Score: 0.2881 | "Team bons petits plats" -vs- "salade de pates c une dinguerie" 
# Score: 0.4529 | "sa commence a quelle heure de base popcorn ?" -vs- "√ßa commence √† √™tre long la" 
# Score: 0.5805 | "BibleThump" -vs- "NotLikeThis" 

```

## Entrainement

* 500 000 messages twitchs √©chantillonn√©s (cf description donn√©es des mod√®les de bases)
* Batch size: 24
* Epochs: 24
* Loss: MultipleNegativesRankingLoss

_A noter:_ 
* _ConvBert a √©t√© entrain√© avec un longueur de 128 tokens max, mais est utilis√© pour 512 dans ce mod√®le. Pas de probl√®me._
* _La loss d'apprentissage n'est pas encore disponible: peu de visibilit√© sur les performances._

L'ensemble du code d'entrainement sur le github public [lincoln/twitchatds](https://github.com/Lincoln-France/twitchatds).

## Application:

Nous avons utilis√© une approche d√©tourn√©e de [BERTopic](https://maartengr.github.io/BERTopic/) pour r√©aliser un clustering d'un stream en prenant en compte la dimension temporelle: i.e. le nombre de seconde √©coul√©e depuis le d√©but du stream.

![approche_bertopic_lincoln](assets/approche_lincoln_topic_clustering_twitch.jpg)

Globalement, l'approche donnes des r√©sultats satisfaisant pour identifier des messages dit "similaires" r√©currents. L'approche en revanche est fortement influenc√©e par la ponctuation et la structure d'un message. Cela est largement explicable par le manque d'entrainement de l'ensemble des mod√®les et une volum√©trie faible.

### Clustering √©mission "Backseat":

Entre 19h30 et 20h00:

![1930_2000](./assets/scale_600_1930_2000.png)

üéûÔ∏è en vid√©o: [youtu.be/EcjvlE9aTls](https://youtu.be/EcjvlE9aTls)

### Exemple regroupement √©mission "PopCorn":

```txt
-------------------- LABEL 106 --------------------
circus (0.88)/sulli (0.23)/connu (0.19)/jure (0.12)/aime (0.11)
silouhette moyenne: 0.04
-------------------- LABEL 106 --------------------
2021-03-30 20:10:22  0.01: les gosse c est des animaux 
2021-03-30 20:12:11 -0.03: oue c connu 
2021-03-30 20:14:15  0.03: oh le circus !! <3 
2021-03-30 20:14:19  0.12: le circus l'anciennnee 
2021-03-30 20:14:22  0.06: jure le circus ! 
2021-03-30 20:14:27 -0.03: le sulli 
2021-03-30 20:14:31  0.09: le circus??? j'aime po 
2021-03-30 20:14:34  0.11: le Circus, hors de prix ! 
2021-03-30 20:14:35 -0.09: le Paddock a Rignac en Aveyron 
2021-03-30 20:14:39  0.11: le circus >< 
2021-03-30 20:14:39  0.04: le Titty Twister de Besan√ßon 

-------------------- LABEL 17 --------------------
pates (0.12)/riz (0.09)/p√¢tes (0.09)/salade (0.07)/emission (0.07)
silouhette moyenne: -0.05
-------------------- LABEL 17 --------------------
2021-03-30 20:11:18 -0.03: Des nanimaux trop beaux ! 
2021-03-30 20:13:11 -0.01: episode des simpsons √ßa... 
2021-03-30 20:13:41 -0.01: des le debut d'emission ca tue mdrrrrr 
2021-03-30 20:13:50  0.03: des "lasagnes" 
2021-03-30 20:14:37 -0.18: poubelle la vie 
2021-03-30 20:15:13  0.03: Une omelette 
2021-03-30 20:15:35 -0.19: salade de bite 
2021-03-30 20:15:36 -0.00: hahaha ce gastronome 
2021-03-30 20:15:43 -0.08: salade de pates c une dinguerie 
2021-03-30 20:17:00 -0.11: Une bonne femme ! 
2021-03-30 20:17:06 -0.05: bouffe des graines 
2021-03-30 20:17:08 -0.06: des pokeball ? 
2021-03-30 20:17:11 -0.12: le choux fleur cru 
2021-03-30 20:17:15  0.05: des pockeball ? 
2021-03-30 20:17:27 -0.00: du chou fleur crue 
2021-03-30 20:17:36 -0.09: un r√¢gout de Meynia !!!! 
2021-03-30 20:17:43 -0.07: une line up Sa rd o ch Zack Ponce my dream 
2021-03-30 20:17:59 -0.10: P√¢tes/10 
2021-03-30 20:18:09 -0.05: Team bons petits plats 
2021-03-30 20:18:13 -0.10: pate level 
2021-03-30 20:18:19 -0.03: que des trucs tr√®s basiques 
2021-03-30 20:18:24  0.03: des pates et du jambon c'est de la cuisine? 
2021-03-30 20:18:30  0.05: Des pates et du riz ouai 
2021-03-30 20:18:37 -0.02: des gnocchis √† la poele c'est cuisiner ? 
2021-03-30 20:18:50 -0.03: P√¢tes √† pizzas, pulled pork, carbonade flamande, etc.. 
2021-03-30 20:19:01 -0.11: Des p√¢tes ou du riz √ßa compte ? 
2021-03-30 20:19:22 -0.21: le noob 
2021-03-30 20:19:47 -0.02: Une bonne escalope de milanaise les gars 
2021-03-30 20:20:05 -0.04: faites des gratins et des quiches 

-------------------- LABEL 67 --------------------
1 1 (0.25)/1 (0.19)/ (0.0)/ (0.0)/ (0.0)
silouhette moyenne: 0.96
-------------------- LABEL 67 --------------------
2021-03-30 20:24:17  0.94: +1 
2021-03-30 20:24:37  0.97: +1 
2021-03-30 20:24:37  0.97: +1 
2021-03-30 20:24:38  0.97: +1 
2021-03-30 20:24:39  0.97: +1 
2021-03-30 20:24:43  0.97: +1 
2021-03-30 20:24:44  0.97: +1 
2021-03-30 20:24:47  0.97: +1 
2021-03-30 20:24:49  0.97: +1 
2021-03-30 20:25:00  0.97: +1 
2021-03-30 20:25:21  0.95: +1 
2021-03-30 20:25:25  0.95: +1 
2021-03-30 20:25:28  0.94: +1 
2021-03-30 20:25:30  0.94: +1 
```

## Full Model Architecture

```
SentenceTransformer(
  (0): Transformer({'max_seq_length': 512, 'do_lower_case': False}) with Transformer model: ConvBertModel 
  (1): Pooling({'word_embedding_dimension': 256, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})
)
```

## Mod√®les:

* [2021twitchfr-conv-bert-small](https://huggingface.co/lincoln/2021twitchfr-conv-bert-small)
* [2021twitchfr-conv-bert-small-mlm](https://huggingface.co/lincoln/2021twitchfr-conv-bert-small-mlm)
* [2021twitchfr-conv-bert-small-mlm-simcse](https://huggingface.co/lincoln/2021twitchfr-conv-bert-small-mlm-simcse)