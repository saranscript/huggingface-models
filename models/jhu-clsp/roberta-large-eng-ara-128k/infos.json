{"modelId": "jhu-clsp/roberta-large-eng-ara-128k", "sha": "8557e84530e0833f9f9c647d277e4ff5881d135e", "lastModified": "2021-09-14T19:37:39.000Z", "tags": ["pytorch", "tf", "xlm-roberta", "fill-mask", "ar", "en", "dataset:arabic_billion_words", "dataset:cc100", "dataset:gigaword", "dataset:oscar", "dataset:wikipedia", "transformers", "bert", "roberta", "exbert", "license:mit", "autonlp_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "sentencepiece.bpe.model"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf_model.h5"}, {"rfilename": "tokenizer_config.json"}], "config": {"architectures": ["XLMRobertaForMaskedLM"], "model_type": "xlm-roberta"}, "private": false, "downloads": 115, "library_name": "transformers", "likes": 3}