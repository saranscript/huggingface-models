{"modelId": "macedonizer/mk-roberta-base", "sha": "eda071f5e775acaaf668d5b30d9f7db3bccb4d06", "lastModified": "2021-09-22T08:58:49.000Z", "tags": ["pytorch", "jax", "roberta", "fill-mask", "mk", "dataset:wiki-mk", "dataset:time-mk-news-2010-2015", "transformers", "masked-lm", "license:apache-2.0", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "blaze-koneski.jpg"}, {"rfilename": "config.json"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "lets-talk-about-nlp-blaze-koneski-2.jpg"}, {"rfilename": "lets-talk-about-nlp-blaze-koneski.jpg"}, {"rfilename": "merges.txt"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "scheduler.pt"}, {"rfilename": "trainer_state.json"}, {"rfilename": "training_args.bin"}, {"rfilename": "vocab.json"}], "config": {"architectures": ["RobertaForMaskedLM"], "model_type": "roberta"}, "private": false, "downloads": 2385, "library_name": "transformers", "likes": 0}