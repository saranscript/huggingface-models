{"modelId": "SauravMaheshkar/clr-pretrained-distilbert-base-uncased", "sha": "ee46573a22a9ef7f47eb138dd0290a3a94e4c713", "lastModified": "2021-09-23T15:57:56.000Z", "tags": ["pytorch", "distilbert", "fill-mask", "dataset:Commonlit-Readibility", "transformers", "kaggle", "license:cc0-1.0", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": ".gitignore"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["DistilBertForMaskedLM"], "model_type": "distilbert"}, "private": false, "downloads": 5, "library_name": "transformers", "likes": 0}