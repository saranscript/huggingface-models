{"modelId": "SauravMaheshkar/clr-pretrained-electra-large", "sha": "fbed12c478a9a6904bc8e56302447f3402c2c28d", "lastModified": "2021-09-23T15:58:01.000Z", "tags": ["pytorch", "electra", "pretraining", "dataset:Commonlit-Readibility", "transformers", "kaggle", "license:cc0-1.0", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": ".gitignore"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["ElectraForPreTraining"], "model_type": "electra"}, "private": false, "downloads": 0, "library_name": "transformers", "likes": 0}