{"modelId": "zlucia/bert-double", "sha": "0ce1a5b13ad6781ac7784521d1b56e1f48c89cf7", "lastModified": "2021-07-02T05:54:19.000Z", "tags": ["pytorch", "tf", "jax", "bert", "pretraining", "en", "arxiv:2104.08671", "arxiv:1810.04805", "arxiv:1903.10676", "transformers", "fill-mask", "autonlp_compatible", "infinity_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "flax_model.msgpack"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tf_model.h5"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["BertForPreTraining"], "model_type": "bert"}, "private": false, "downloads": 8, "library_name": "transformers", "likes": 0}