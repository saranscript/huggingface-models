{"modelId": "SkolkovoInstitute/roberta_toxicity_classifier", "sha": "3cd450864abaa584b1620f5bea9169a2226db3eb", "lastModified": "2021-10-05T14:54:55.000Z", "tags": ["pytorch", "roberta", "text-classification", "en", "arxiv:1907.11692", "transformers", "toxic comments classification", "infinity_compatible"], "pipeline_tag": "text-classification", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "README.md"}, {"rfilename": "config.json"}, {"rfilename": "merges.txt"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.json"}], "config": {"architectures": ["RobertaForSequenceClassification"], "model_type": "roberta"}, "private": false, "downloads": 4065, "library_name": "transformers", "likes": 3}