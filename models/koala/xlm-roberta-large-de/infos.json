{"modelId": "koala/xlm-roberta-large-de", "sha": "08dcb3ce3813f966a5ef6a290d03c1e828b1f078", "lastModified": "2021-12-06T18:16:37.000Z", "tags": ["pytorch", "xlm-roberta", "fill-mask", "transformers", "autonlp_compatible"], "pipeline_tag": "fill-mask", "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "all_results.json"}, {"rfilename": "config.json"}, {"rfilename": "eval_results.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "sentencepiece.bpe.model"}, {"rfilename": "special_tokens_map.json"}, {"rfilename": "tokenizer.json"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "train_results.json"}, {"rfilename": "trainer_state.json"}, {"rfilename": "training_args.bin"}], "config": {"architectures": ["XLMRobertaForMaskedLM"], "model_type": "xlm-roberta"}, "private": false, "downloads": 90, "library_name": "transformers", "likes": 0}