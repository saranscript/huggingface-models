{"modelId": "enelpi/med-electra-small-30k-discriminator", "sha": "f222cbda2c257676ffe09bd56500d23e540bfeba", "lastModified": "2021-01-16T01:17:53.000Z", "tags": ["pytorch", "electra", "pretraining", "transformers", "infinity_compatible"], "pipeline_tag": null, "siblings": [{"rfilename": ".gitattributes"}, {"rfilename": "config.json"}, {"rfilename": "pytorch_model.bin"}, {"rfilename": "tokenizer_config.json"}, {"rfilename": "vocab.txt"}], "config": {"architectures": ["ElectraForPreTraining"], "model_type": "electra"}, "private": false, "downloads": 8, "library_name": "transformers", "likes": 0}